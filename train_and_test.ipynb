{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8751e9af-6fa3-429e-80ee-e79b57cf328e",
   "metadata": {},
   "source": [
    "# xAI Wake Classifier - Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba790ce6-5b83-40c4-9cf5-736b566557ed",
   "metadata": {},
   "source": [
    "## Required data (run to download the xAI Wakes dataset yet)\n",
    "* For the .csv with the target values for training and a set of pretrained weights, go to: https://drive.google.com/drive/folders/1CUIQy77qIsx2vIdJB7D95UEzCv5_YZDL?usp=sharing\n",
    "* For the dataset, run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c56b1e0-d75d-43cb-970c-67d72a9bf4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_file(url, filename):\n",
    "    \"\"\"\n",
    "    Download a file from the specified URL and save it locally.\n",
    "    \"\"\"\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # Total size in bytes\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    block_size = 1024  # 1 Kibibyte\n",
    "\n",
    "    with open(filename, 'wb') as file, tqdm(\n",
    "        total=total_size, unit='iB', unit_scale=True\n",
    "    ) as bar:\n",
    "        for data in response.iter_content(block_size):\n",
    "            bar.update(len(data))\n",
    "            file.write(data)\n",
    "\n",
    "# URL of the file to be downloaded\n",
    "url = \"https://zenodo.org/records/10018939/files/xAIWakes.zip?download=1\"\n",
    "\n",
    "# Local filename to save the downloaded file\n",
    "filename = \"xAIWakes.zip\"\n",
    "\n",
    "# Download the file\n",
    "download_file(url, filename)\n",
    "\n",
    "print(f\"Downloaded '{filename}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f82509-5a72-4601-bb93-412054d53aab",
   "metadata": {},
   "source": [
    "* Extract the downloaded dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29688154-5944-468e-bb83-fb7ac70a2801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Specify the path to the zip file and the extraction directory\n",
    "zip_path = 'xAIWakes.zip'\n",
    "extract_to = 'xAIWakes'\n",
    "\n",
    "# Unzipping the file\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2abd9b0-31d5-4315-af2c-fd3686b1d332",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "077dfce9-ec91-4bef-a93b-40be59db268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.utilities.types import STEP_OUTPUT\n",
    "from pytorch_lightning.utilities.types import TRAIN_DATALOADERS, EVAL_DATALOADERS\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "import torchmetrics\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "from torchmetrics.classification import BinaryF1Score\n",
    "from torchmetrics.classification import BinaryConfusionMatrix\n",
    "\n",
    "import numpy\n",
    "import numpy as np\n",
    "from numpy import logspace\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime # Used only to name savefig of confusion matrix\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io\n",
    "import tifffile\n",
    "from pathlib import Path\n",
    "import imageio.v2 as imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8fd981-9f1e-421e-9e86-79d8f609dfc9",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "026218e2-845a-447a-bd40-4256a952bbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed\n",
    "SEED = 41\n",
    "\n",
    "# Training hyperparameters\n",
    "IN_CHANNELS = 4\n",
    "NUM_CLASSES = 2\n",
    "LEARNING_RATE = 0.000310823572 # Obtained through Grey Wolf Optimization\n",
    "BATCH_SIZE = 21 # Obtained through Grey Wolf Optimization\n",
    "NUM_EPOCHS = 21\n",
    "\n",
    "# Dataset\n",
    "DATA_DIR = rf'xAIWakes/xAIWakes/'\n",
    "CSV_DIR = rf'xAIWakes_dataset.csv'\n",
    "\n",
    "NUM_WORKERS = 0 # 4\n",
    "TRANSFORM = v2.Compose([\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.RandomVerticalFlip(p=0.5),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "TRANSFORM_SIMPLE = torchvision.transforms.ToTensor()\n",
    "\n",
    "# Compute related\n",
    "ACCELERATOR = \"gpu\" # Change to use cpu\n",
    "DEVICES = [0]\n",
    "#PRECISION = 16\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # Change ACCELLERATOR to use this\n",
    "\n",
    "# Logs\n",
    "LOGS_DIR = rf\"tb_logs\"\n",
    "CONF_MATRIX_DIR = rf\"tb_logs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcccddba-b612-409e-aefb-182facc5b7ba",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43d0f78-18c3-483b-8242-7713b02e3460",
   "metadata": {},
   "source": [
    "* Transform the xAIWakes dataset to suit the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe7f1316-bfa3-4af1-9b48-f6746ef9e393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(idx):\n",
    "    \n",
    "    def correct_dim(img):\n",
    "        # If the image is not already in grayscale, convert it\n",
    "        if len(img.shape) == 3 and img.shape[2] == 3:  # Assuming the image is RGB\n",
    "            img_gray = img[:, :, 0]\n",
    "        else:\n",
    "            img_gray = img\n",
    "        return img_gray\n",
    "\n",
    "    resize_transform = transforms.Resize((256,256), antialias=True)\n",
    "\n",
    "    b2 = [x for x in Path('xAIWakes/xAIWakes/B2').glob('**/*') if x.is_file()]\n",
    "    b3 = [x for x in Path('xAIWakes/xAIWakes/B3').glob('**/*') if x.is_file()]\n",
    "    b4 = [x for x in Path('xAIWakes/xAIWakes/B4').glob('**/*') if x.is_file()]\n",
    "    b8 = [x for x in Path('xAIWakes/xAIWakes/B8').glob('**/*') if x.is_file()]\n",
    "\n",
    "    # Exclude unwanted indices\n",
    "    exclude_indices = [4, 80, 84, 87]  # Because B2 no_wake has some images in excess\n",
    "    b2 = [b2[i] for i in range(len(b2)) if i not in exclude_indices] # Because B2 no_wake has some images in excess\n",
    "    \n",
    "    b2_idx = b2[idx]\n",
    "    b3_idx = b3[idx]\n",
    "    b4_idx = b4[idx]\n",
    "    b8_idx = b8[idx]\n",
    "\n",
    "    #TEST\n",
    "    im_b2 = imageio.imread(b2_idx)\n",
    "    im_b3 = imageio.imread(b3_idx)\n",
    "    im_b4 = imageio.imread(b4_idx)\n",
    "    im_b8 = imageio.imread(b8_idx)\n",
    "\n",
    "    # Correct the dimensions\n",
    "    im_b2 = correct_dim(im_b2)\n",
    "    im_b3 = correct_dim(im_b3)\n",
    "    im_b4 = correct_dim(im_b4)\n",
    "    im_b8 = correct_dim(im_b8)\n",
    "    \n",
    "    # Convert NumPy arrays to PIL Images\n",
    "    im_b2 = Image.fromarray(im_b2)\n",
    "    im_b3 = Image.fromarray(im_b3)\n",
    "    im_b4 = Image.fromarray(im_b4)\n",
    "    im_b8 = Image.fromarray(im_b8)\n",
    "    \n",
    "    # Apply resizing transformation\n",
    "    im_b2 = resize_transform(im_b2)\n",
    "    im_b3 = resize_transform(im_b3)\n",
    "    im_b4 = resize_transform(im_b4)\n",
    "    im_b8 = resize_transform(im_b8)\n",
    "    \n",
    "    im_stack = np.stack((im_b2, im_b3, im_b4, im_b8), axis=0)\n",
    "    #print(\"CHECK:\", im_stack.shape)\n",
    "    return im_stack.astype(np.float32)\n",
    "\n",
    "class xAIWakesDataset(Dataset):\n",
    "    def __init__(self, csv_dir, root_dir, transform=None):\n",
    "        super().__init__()\n",
    "        self.annotations = pd.read_csv(csv_dir)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations) # XAI has 269 images\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        image = read_img(index)\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))       \n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        image = image.permute(1, 0, 2)\n",
    "        #print(\"CHECK_2:\",image.shape)\n",
    "        return (image, y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e921a7-b191-40c5-b273-e43747705789",
   "metadata": {},
   "source": [
    "* Define the Lightning data module\n",
    "* Dataset split as 60% Training, 20% for validation and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edb57348-e1c4-462a-aaa2-7ef8f54cf5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class xAIWakesDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, csv_file, root_dir, batch_size, num_workers, transform=None):\n",
    "        super().__init__()\n",
    "        self.csv_file = csv_file\n",
    "        self.root_dir = root_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.transform = transform\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # Left empty as data is already downloaded and preprocessed\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage):\n",
    "        my_ds = xAIWakesDataset(self.csv_file, self.root_dir, self.transform)\n",
    "        self.train_ds, self.val_ds, self.test_ds = random_split(my_ds, [0.6, 0.2, 0.2])\n",
    "        self.predict_ds = my_ds\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True,\n",
    "            #persistent_workers=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "            #persistent_workers=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "            #persistent_workers=True,\n",
    "        )\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.predict_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "            #persistent_workers=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6315e535-95f4-4dd0-8017-64f14dfc3ed0",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f20b1b43-d55a-4a3f-ba9c-2b045ca8f578",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonConv(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=(3, 3),\n",
    "                stride=(1, 1),\n",
    "                padding=(1, 1),\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cae5d85-0526-41b6-8084-6dff73dfad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WakeClassifier(nn.Module):\n",
    "    def __init__(self, in_channels=4, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            CommonConv(in_channels=in_channels, out_channels=16),\n",
    "            CommonConv(in_channels=16, out_channels=32),\n",
    "            CommonConv(in_channels=32, out_channels=64),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(64 * 32 * 32, 512),  # Adjust input size based on your image dimensions\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes),  # Output layer with 2 classes\n",
    "            nn.Dropout(p=0.4),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be2ebd99-50d9-4401-8dad-83b5f6bd1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WakeClassifierPlModule(pl.LightningModule):\n",
    "    def __init__(self, in_channels=4, num_classes=2, learning_rate=1e-3):\n",
    "        super(WakeClassifierPlModule, self).__init__()\n",
    "        self.lr = learning_rate\n",
    "        self.model = WakeClassifier(num_classes=2)\n",
    "\n",
    "        # Other\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.accuracy = BinaryAccuracy()\n",
    "        self.test_accuracy = 0.0 # for hyperparameter optimization\n",
    "        self.f1_score = BinaryF1Score()\n",
    "        self.conf_matrix = BinaryConfusionMatrix()\n",
    "        self.conf_matrix_pred = BinaryConfusionMatrix()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers with ReLU activation, batch normalization, and max pooling\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        loss, scores, y = self._common_step(batch, batch_idx)\n",
    "        accuracy = self.accuracy(torch.argmax(scores, dim=1), y)\n",
    "        f1_score = self.f1_score(torch.argmax(scores, dim=1), y)\n",
    "        self.log_dict({\n",
    "            'train_loss': loss, \n",
    "            'train_accuracy': accuracy,\n",
    "            'train_f1_score': f1_score,\n",
    "            },\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True\n",
    "            )\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        loss, scores, y = self._common_step(batch, batch_idx)\n",
    "        self.accuracy.update(torch.argmax(scores, dim=1), y)\n",
    "        self.f1_score.update(torch.argmax(scores, dim=1), y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        loss, scores, y = self._common_step(batch, batch_idx)\n",
    "        accuracy = self.accuracy(torch.argmax(scores, dim=1), y)\n",
    "        f1_score = self.f1_score(torch.argmax(scores, dim=1), y)\n",
    "        self.conf_matrix.update(torch.argmax(scores, dim=1), y)\n",
    "        self.conf_matrix.compute()\n",
    "        self.log_dict({\n",
    "            'test_loss': loss, \n",
    "            'test_accuracy': accuracy,\n",
    "            'test_f1_score': f1_score,\n",
    "            },\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True\n",
    "            )\n",
    "        return loss\n",
    "\n",
    "    def on_test_end(self):\n",
    "        fig_, ax_ = self.conf_matrix.plot()  # to plot and save confusion matrix\n",
    "        plt.xlabel('Prediction')\n",
    "        plt.ylabel('Class')\n",
    "        current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        plt.savefig(rf\".\\tb_logs\\confusion_matrix_{current_datetime}.png\")\n",
    "        #plt.show()\n",
    "\n",
    "    def _common_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        scores = self.forward(x)\n",
    "        loss = self.loss_fn(scores, y)\n",
    "        return loss, scores, y\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        scores = self.forward(x)\n",
    "        preds = torch.argmax(scores, dim=1)\n",
    "        accuracy = self.accuracy(preds, y)\n",
    "        f1_score = self.f1_score(preds, y)\n",
    "        self.conf_matrix_pred.update(preds, y)\n",
    "        self.conf_matrix_pred.compute()\n",
    "\n",
    "        print(f\" - Accuracy: {accuracy:.3f}, F1-score: {f1_score:.3f}\")\n",
    "        return preds\n",
    "\n",
    "    def on_predict_end(self):\n",
    "        fig_, ax_ = self.conf_matrix_pred.plot()\n",
    "        plt.xlabel('Prediction')\n",
    "        plt.ylabel('Class')\n",
    "        current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        plt.savefig(rf\".\\tb_logs\\confusion_matrix_predictions_{current_datetime}.png\")\n",
    "        plt.show()  # test block=False\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr) # 1e-3 is a sane value for lr\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b54eb96-fc45-4ad9-b42f-4275931df12e",
   "metadata": {},
   "source": [
    "#### Tensor shape test\n",
    "Useful to see if the model takes in a tensor with the correct shape, and returns the correct amount of classes. In this case, the desired output is \"torch.Size([4, 2])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3c583b7-9f1a-4591-9af2-ddbb2591321a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "# Basic check\n",
    "model = WakeClassifier()\n",
    "x = torch.randn(4, 4, 256, 256)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3dcba5-fad2-4f61-9b65-41dca78cc121",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab6efab-5d22-4e10-af19-d3a6886b2537",
   "metadata": {},
   "source": [
    "Note: workers are set to 0 and are set to not be persistent in the dataloaders because of some issue with notebook. For information on this issue, refer to this (https://github.com/pytorch/pytorch/issues/5301)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ba557d-8d04-4fc6-aaae-b045e85e8a34",
   "metadata": {},
   "source": [
    "* For reproducibility's sake, it is important to set the seed for all pseudo-random processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "564474a7-40d1-4871-ad71-4cadf721787b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 41\n"
     ]
    }
   ],
   "source": [
    "seed = pl.seed_everything(seed=SEED, workers=True) # For reproducibility\n",
    "torch.set_float32_matmul_precision(\"medium\") # to make lightning happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "628a3597-d4b2-4ebf-baa6-a6aac9e245f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                  | Params\n",
      "-----------------------------------------------------------\n",
      "0 | model            | WakeClassifier        | 33.6 M\n",
      "1 | loss_fn          | CrossEntropyLoss      | 0     \n",
      "2 | accuracy         | BinaryAccuracy        | 0     \n",
      "3 | f1_score         | BinaryF1Score         | 0     \n",
      "4 | conf_matrix      | BinaryConfusionMatrix | 0     \n",
      "5 | conf_matrix_pred | BinaryConfusionMatrix | 0     \n",
      "-----------------------------------------------------------\n",
      "33.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "33.6 M    Total params\n",
      "134.319   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\andre\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:293: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 8/8 [00:20<00:00,  0.38it/s, v_num=2]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 13.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:02<00:01,  0.78it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.79it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 8/8 [00:18<00:00,  0.44it/s, v_num=2, train_loss=7.930, train_accuracy=0.503, train_f1_score=0.411]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 12.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:02<00:01,  0.85it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.85it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 8/8 [00:18<00:00,  0.44it/s, v_num=2, train_loss=5.300, train_accuracy=0.615, train_f1_score=0.525]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 12.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:02<00:01,  0.83it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.77it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 8/8 [00:18<00:00,  0.44it/s, v_num=2, train_loss=2.440, train_accuracy=0.733, train_f1_score=0.665]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 43.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:02<00:01,  0.94it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.86it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 8/8 [00:18<00:00,  0.42it/s, v_num=2, train_loss=0.678, train_accuracy=0.776, train_f1_score=0.708]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00,  6.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:02<00:01,  0.79it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.79it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 8/8 [00:17<00:00,  0.46it/s, v_num=2, train_loss=0.609, train_accuracy=0.851, train_f1_score=0.829]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 13.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:02<00:01,  0.84it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.82it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 8/8 [00:18<00:00,  0.44it/s, v_num=2, train_loss=0.518, train_accuracy=0.826, train_f1_score=0.793]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 12.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:02<00:01,  0.83it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.81it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 8/8 [00:18<00:00,  0.44it/s, v_num=2, train_loss=0.326, train_accuracy=0.845, train_f1_score=0.791]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00,  6.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:02<00:01,  0.91it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.88it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 8/8 [00:17<00:00,  0.46it/s, v_num=2, train_loss=0.723, train_accuracy=0.845, train_f1_score=0.812]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 12.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:02<00:01,  0.84it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.83it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 8/8 [00:17<00:00,  0.46it/s, v_num=2, train_loss=0.320, train_accuracy=0.919, train_f1_score=0.897]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 36.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:02<00:01,  0.94it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.90it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 8/8 [00:17<00:00,  0.44it/s, v_num=2, train_loss=0.212, train_accuracy=0.907, train_f1_score=0.895]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 47.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:02<00:01,  0.93it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.84it/s]\u001b[A\n",
      "Epoch 11: 100%|██████████| 8/8 [00:17<00:00,  0.46it/s, v_num=2, train_loss=0.165, train_accuracy=0.907, train_f1_score=0.894]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 38.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:02<00:01,  0.92it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.90it/s]\u001b[A\n",
      "Epoch 12: 100%|██████████| 8/8 [00:18<00:00,  0.44it/s, v_num=2, train_loss=0.229, train_accuracy=0.913, train_f1_score=0.891]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 30.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:02<00:01,  0.83it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.83it/s]\u001b[A\n",
      "Epoch 13: 100%|██████████| 8/8 [00:17<00:00,  0.45it/s, v_num=2, train_loss=0.127, train_accuracy=0.944, train_f1_score=0.935]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 30.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:02<00:01,  0.91it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.85it/s]\u001b[A\n",
      "Epoch 14: 100%|██████████| 8/8 [00:17<00:00,  0.45it/s, v_num=2, train_loss=0.114, train_accuracy=0.938, train_f1_score=0.926]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 13.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:02<00:01,  0.85it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.84it/s]\u001b[A\n",
      "Epoch 15: 100%|██████████| 8/8 [00:17<00:00,  0.46it/s, v_num=2, train_loss=0.104, train_accuracy=0.944, train_f1_score=0.936]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 11.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:02<00:01,  0.79it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.79it/s]\u001b[A\n",
      "Epoch 16: 100%|██████████| 8/8 [00:17<00:00,  0.46it/s, v_num=2, train_loss=0.147, train_accuracy=0.913, train_f1_score=0.890]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 14.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:02<00:01,  0.88it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.80it/s]\u001b[A\n",
      "Epoch 17: 100%|██████████| 8/8 [00:17<00:00,  0.46it/s, v_num=2, train_loss=0.143, train_accuracy=0.901, train_f1_score=0.879]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 14.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:02<00:01,  0.86it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.82it/s]\u001b[A\n",
      "Epoch 18: 100%|██████████| 8/8 [00:17<00:00,  0.45it/s, v_num=2, train_loss=0.0732, train_accuracy=0.957, train_f1_score=0.950]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 31.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:02<00:01,  0.91it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.86it/s]\u001b[A\n",
      "Epoch 19: 100%|██████████| 8/8 [00:17<00:00,  0.45it/s, v_num=2, train_loss=0.131, train_accuracy=0.919, train_f1_score=0.896] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 12.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:02<00:01,  0.86it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.85it/s]\u001b[A\n",
      "Epoch 20: 100%|██████████| 8/8 [00:17<00:00,  0.45it/s, v_num=2, train_loss=0.106, train_accuracy=0.919, train_f1_score=0.905]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 12.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:02<00:01,  0.88it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.82it/s]\u001b[A\n",
      "Epoch 20: 100%|██████████| 8/8 [00:23<00:00,  0.34it/s, v_num=2, train_loss=0.138, train_accuracy=0.913, train_f1_score=0.895]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=21` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 8/8 [00:25<00:00,  0.32it/s, v_num=2, train_loss=0.138, train_accuracy=0.913, train_f1_score=0.895]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\andre\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.76it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        val_loss            1.1895912885665894\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\andre\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.82it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy          0.849056601524353\n",
      "      test_f1_score         0.7799917459487915\n",
      "        test_loss            1.080797553062439\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "The test accuracy is:  0.849056601524353\n"
     ]
    }
   ],
   "source": [
    "logger = TensorBoardLogger(save_dir=LOGS_DIR, name=f\"wakeclassifier_model_dropout_v0_lr{LEARNING_RATE}_bs{BATCH_SIZE}\")\n",
    "#profiler = PyTorchProfiler(\n",
    "#    on_trace_ready=torch.profiler.tensorboard_trace_handler(\"tb_logs/profiler0\"),\n",
    "#    schedule=torch.profiler.schedule(skip_first=5, wait=1, warmup=1, active=20),\n",
    "#)\n",
    "model = WakeClassifierPlModule(\n",
    "    in_channels=IN_CHANNELS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    learning_rate=LEARNING_RATE,\n",
    ")\n",
    "dm = xAIWakesDataModule( # self, csv_file, root_dir, batch_size, num_workers, transform=None)\n",
    "    csv_file=CSV_DIR,\n",
    "    root_dir=DATA_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    transform=TRANSFORM_SIMPLE,\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=ACCELERATOR,\n",
    "    devices=DEVICES,\n",
    "    min_epochs=1,\n",
    "    max_epochs=NUM_EPOCHS,\n",
    "    fast_dev_run=False, #check for a fast run \n",
    "    overfit_batches=False, # check to overfit a batch. Do this before trying to train on the whole dataset\n",
    "    logger=logger,\n",
    "    log_every_n_steps=5,\n",
    "    check_val_every_n_epoch=5,\n",
    "    #profiler=profiler,\n",
    "    #callbacks=[cb],\n",
    ")\n",
    "trainer.fit(model, dm)\n",
    "trainer.validate(model, dm)\n",
    "results = trainer.test(model, dm)\n",
    "print(\"The test accuracy is: \", results[0].get('test_accuracy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb827462-525b-4a9b-b1de-7e7acff914d4",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1c2fcd-58cb-4494-81ae-d72d1c1013a4",
   "metadata": {},
   "source": [
    "* Currently set to do inference on a the whole dataset. Change the predict_step, the predict dataloader, etc. to change this. \n",
    "* Download pre-trained weights from here: https://drive.google.com/uc?export=download&id=1NfR57Liq_1-lplvjsxMLUaB_64A8PFSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abd7976f-ae99-4669-a18d-f07cf46e3bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at epoch=19-step=160.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at epoch=19-step=160.ckpt\n",
      "C:\\Users\\andre\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0:   0%|          | 0/13 [00:00<?, ?it/s] - Accuracy: 1.000, F1-score: 0.000\n",
      "Predicting DataLoader 0:   8%|▊         | 1/13 [00:00<00:01,  6.09it/s] - Accuracy: 1.000, F1-score: 0.000\n",
      "Predicting DataLoader 0:  15%|█▌        | 2/13 [00:01<00:07,  1.39it/s] - Accuracy: 1.000, F1-score: 0.000\n",
      "Predicting DataLoader 0:  23%|██▎       | 3/13 [00:02<00:08,  1.21it/s] - Accuracy: 1.000, F1-score: 0.000\n",
      "Predicting DataLoader 0:  31%|███       | 4/13 [00:03<00:07,  1.16it/s] - Accuracy: 0.905, F1-score: 0.000\n",
      "Predicting DataLoader 0:  38%|███▊      | 5/13 [00:04<00:07,  1.07it/s] - Accuracy: 0.810, F1-score: 0.000\n",
      "Predicting DataLoader 0:  46%|████▌     | 6/13 [00:05<00:06,  1.07it/s] - Accuracy: 0.905, F1-score: 0.500\n",
      "Predicting DataLoader 0:  54%|█████▍    | 7/13 [00:06<00:05,  1.04it/s] - Accuracy: 0.810, F1-score: 0.895\n",
      "Predicting DataLoader 0:  62%|██████▏   | 8/13 [00:08<00:05,  0.98it/s] - Accuracy: 0.905, F1-score: 0.950\n",
      "Predicting DataLoader 0:  69%|██████▉   | 9/13 [00:09<00:04,  0.97it/s] - Accuracy: 0.905, F1-score: 0.950\n",
      "Predicting DataLoader 0:  77%|███████▋  | 10/13 [00:10<00:03,  0.95it/s] - Accuracy: 0.857, F1-score: 0.923\n",
      "Predicting DataLoader 0:  85%|████████▍ | 11/13 [00:11<00:02,  0.95it/s] - Accuracy: 0.762, F1-score: 0.865\n",
      "Predicting DataLoader 0:  92%|█████████▏| 12/13 [00:12<00:01,  0.94it/s] - Accuracy: 0.938, F1-score: 0.968\n",
      "Predicting DataLoader 0: 100%|██████████| 13/13 [00:13<00:00,  0.96it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAG5CAYAAADiXxGlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoUElEQVR4nO3deXxU9b3/8fdkmxCSSSAhQBZ2EVmDrCIgixEqAvGqCFKE0lat2kqlikstFGlx3+utV7aL3p8I7oqiooLKjuyETQQMELJAyITsmTm/PyIjaRIy2Zj45fV8PPJ4dM4y85ka8sqcOXNisyzLEgAAhvDz9QAAANQlwgYAMAphAwAYhbABAIxC2AAARiFsAACjEDYAgFEIGwDAKAG+HuBCcbvdOn78uMLCwmSz2Xw9DgCgmizLUk5OjmJiYuTnV/nrsosmbMePH1d8fLyvxwAA1FJKSori4uIqXX/RhC0sLEySdGRLGzlCOQILM13fsZuvRwDqTYmK9a0+9vw8r8xFE7azhx8doX5yhBE2mCnAFujrEYD689OVjat6O4mf8AAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMEuDrAdAwfbe9QCu/ztfGrQXatK1Ax1JdkiRXaocKt//g01y9s/yMtu4sVGpaibJz3GoS7q9ePez6w5RwXZfYuML9CgstPf/qaS19/4z2/1Ck4hJLMc0DNHxQiB74UxO1ax1Yb88RqK5TVrq26Osqt2unzmpn63wBJkJFCBsqNOfZLH3waa7X27+2zKl3P85Vl0uD1PfyYIWF+ulISrFWfJmnFV/m6YE/NtE/Hooss09BgVvDbzym9d8VKiLcT4OvaKRgu01bdxZq/v9zaukHOfrirVj16hFc108PqBG7gtVSrStcZ8nSCf0oSYpQ1IUcC/+BsKFCV/QOVvfOQeqdEKw+CXa163tEhYVWpds/dE9T/fuJaEU29S+zfMOWAl0z7pgefylL468PVbfL7J51r77u1PrvCtUnwa5P34xRuKN0X5fL0p//lql/LcjWX2Zl6qt34+rnSQLV1NjmUBf1qXBdppWqE/pRdjVSEzW7wJPhXLzHhgrdf3cT/f3+SI2+prFaRFf9+0/PbvZyUZOkfpcHa9zYMFmWtGpNfpl1X68vvT3t9ghP1CTJ39+mv9/XVJK0aVthbZ4GcMGcfbXWUq1ks9l8PM3FjbCh3gX+1MXAwLL/2O1BVf/jryiWQEPjskqUoeOSpBaVHKrEhUPYUK927inU0g/OKDBQSrwqpMy6xCGlt5975bSynS7PcpfL0swnT0mSpk4Iu3DDAjWUrmNyyaUwRSjU5vD1OBc93mNDnfrws9KzI4uLLaUcK9HazQUKDLTplaei1b5N2TMcf31DmD79Kk9vvndG7foe0YA+wQq227RlR6HSMlz6y50R+uufm/romQDeS/3pMGQLtfLxJJB+IWFbv369OnXqpIiICF+Pgirs2F2oxUtzPLcbBdv07KNRmnRj+Vde/v42vfZSc7WKDdCT/zqtj1fmedZd3s2uYQMbyd+f9yrQsBVa+cpSumyyEbYGokEfivzXv/6lqKgojR8/Xv369dMTTzyhoqIiX4+F83j4z03lSu2g3EPttP2reE0Z79Ad92UoaUqqiorKnlWZddqlxJuO6V8LsvXco1H6cUsbZe5pq3cWtlDGSZeu+3Wq3nw/p5JHAhqGE0qRJUtNFS27jY+mNAQNNmybNm3Sq6++qqeeekorV67U1KlT9cwzz+jpp5/2av/CwkI5nc4yX7hwgoP91LWTXS/Nbaa7fxuu5Z/n6aUFp8tsc+/MTK1eV6A5D0Tqj7+LUGzLADWJ8NfYkaF6a34LWZZ0398zVVxc+ccMAF/7+WxIThppKBps2FavXq1Tp05pwoQJ6tChg2bMmKE77rhDb7/9to4cOVLl/nPnzlV4eLjnKz4+/gJMjYr8+qfDkB+s+PkD3y6XpSXvlb4au+G60HL79E4IVttWATqW6tIPR4ovzKBANeVaTuXotPwVoGaK8fU4+EmDDduRI0fUp08fFRf//ENtwoQJiouL02OPPVbl/g8++KCys7M9XykpKfU5Ls4j6qdT9jNO/nzmY3qmS2ePKoc7Kv42DA8r3S8r212/AwI1lKrSX7KjFSt/2y/ilIWLQoMNW+fOnbVmzRqdOnXKs+zSSy/V4MGDtWnTJmVlZZ13f7vdLofDUeYLvrF6XekHsdudc1Zk0wh/BQWV/u/N2wvK7ePMcWvfwdLytY7jBwYaHsuydEKlvzBz0kjD0mDD9utf/1pOp1OffvppmeV9+vRRQUGBNm/e7KPJ8J8yMl169fVs5eWVf2X1+eo8PfDoSUnSlJt//uXCbrdpxNDSCyP/ZVamUtNKPOsKCty664F05eVburJPsFo2J2xoeE4rUwXKk12N1FTRvh4H52iwPzHCwsJ066236plnntGvfvUrxcWVXi9w0KBB+v7778scokTdW74yV/949udXy2fPaBww6udDug//ualGXd1Yuflu3XFfhu79W6Z6dbcrNiZAuXmWDhws0t7vS/87TbstvNx7aU/PitLGLQXatqtIlw08ov69gtUo2E+btxfo+AmXmjbx08tPcM09NEwnPJ9di+cSWg1Mgw2bJP3zn/9U27Zt9cILL+iee+5RbGysVqxYoTZt2qhFixa+Hs9oGSdd2rCl/HUaz1129j2z6Eh/Pf5IpFatzVfyviJt3l4otyW1jPbXzUmhum2SQ0MGhJS7r/ZtArX1i3g98VKWVnyZp282FMiypPiYAN35m1DNuLuJ4mIa9LcoLlJuy6U0HZXEYciGyGZZVoM+l3revHn67//+b+Xm5mrIkCFatmyZbrjhBr388ssKCPD+h57T6VR4eLiy9reTI6zBHoEFamVETIKvRwDqTYlVrFV6X9nZ2ec9b6LB/zr829/+VoMHD9Z7772nPXv2aPHixRo1apSvxwIANFANPmyS1LFjR91///2+HgMA8AvQ4I/J8aYsAKA6GnzYAACoDsIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGKXGYUtLS9PXX3+ttLS0MssPHjyo8ePHq2vXrrr22mu1fv36Wg8JAIC3ahy2xx57TEOHDlV2drZnmdPp1MCBA7Vs2TIlJydrxYoVGj58uA4cOFAnwwIAUJUah23VqlXq3LmzOnbs6Fm2aNEipaWlacKECdq3b5+eeeYZ5efn6+mnn66TYQEAqEqNw3bs2DG1a9euzLLly5crICBAzz33nC655BJNmzZNPXr00OrVq2s9KAAA3qhx2HJychQSEuK57XK5tG7dOvXq1UtRUVGe5Z06ddLRo0drNyUAAF6qcdhiYmK0d+9ez+1vv/1WZ86c0ZAhQ8psV1JSoqCgoBoPCABAddQ4bFdccYV27Nih5557Tjt37tRf//pX2Ww2jR49usx2e/bsUWxsbK0HBQDAGzUO24MPPii73a7p06crISFBa9as0ZAhQzRgwADPNocPH1ZycrL69etXJ8MCAFCVgJru2KVLF3377bd6/vnnlZmZqV69eum+++4rs82nn36qHj16KCkpqbZzAgDgFZtlWZavh7gQnE6nwsPDlbW/nRxhXHAFZhoRk+DrEYB6U2IVa5XeV3Z2thwOR6Xb8RMeAGCUGoftwIEDWrx4sQ4dOlRm+fr169W/f3+Fhoaqc+fOeuedd2o9JAAA3qpx2J5++mlNnTpVgYGBnmVpaWkaMWKENm7cqPz8fO3du1c333yztmzZUifDAgBQlRqH7dtvv1VCQoLi4uI8yxYsWKCcnBzde++9ys/P1zvvvCO3261nnnmmToYFAKAqNQ5bamqqWrduXWbZihUrZLfbNWvWLAUFBSkpKUn9+vXThg0baj0oAADeqHHYCgoK5O/v77ldWFioTZs2qV+/fgoNDfUsb9u2rY4fP167KQEA8FKNwxYXF6cdO3Z4bq9cuVIFBQUaNmxYme3y8/PVuHHjmk8IAEA11Dhsw4YN04EDBzRt2jR9+OGHmjFjhmw2m8aOHVtmu507dyo+Pr7WgwIA4I1aXVIrIiJCL774opKSkpScnKxx48apR48enm12796tgwcP6sorr6yTYQEAqEqNL6nVqlUrbd++XfPmzVNGRoZ69eqlKVOmlNlm69atGjt2rMaNG1fbOQEA8AqX1AIMwiW1YDIuqQUAuCjV+FDkuXJycnTw4EHl5OSosheAgwcProuHAgDgvGoVtl27dmnatGlatWpVpUE7y+Vy1eahAADwSo3DduDAAQ0cOFBOp1NXXnmlUlNTdejQIY0fP14//PCDtmzZopKSEo0ZM0YRERF1OHLt3DRshAL87L4eA6gXzdc5fT0CUG+Kc4uk4VVvV+P32ObMmaOcnBwtXLhQ33zzjQYNGiRJ+r//+z+tW7dOu3fv1sCBA5WcnMy1IgEAF0yNw/bll1/qsssu0+TJkytc36FDB73//vvKyMjQI488UuMBAQCojhqHLT09XZ07d/bcPvvnawoKCjzLIiIiNGTIEH300Ue1GBEAAO/VOGxNmzZVYWFhmduSdOTIkXLbpqen1/RhAAColhqHrW3btmUilpCQIMuy9Oabb3qWZWZmatWqVWrVqlXtpgQAwEs1Dts111yjXbt2eeI2evRoRUVFafbs2Ro/frymT5+uPn36KDs7m0tqAQAumBqf7j9p0iQVFhYqLS1NrVu3VuPGjbVkyRKNGzdOS5cu9WyXmJiohx9+uE6GBQCgKjUOW/v27TV37twyy4YNG6YjR47om2++UVZWljp27KhevXrVekgAALxVJ5fUOlfjxo01cuTIur5bAAC8wkWQAQBG8foV2+LFi2v1QLfeemut9gcAwBteh23KlCmy2WzVfgDLsmSz2QgbAOCC8Dpsf/vb32oUNgAALiSvwzZr1qx6HAMAgLpRrbMiv/zySx09elS9e/cuc53IiiQnJ2vz5s2Kj4/X0KFDazUkAADe8jpsKSkpGjVqlOLj4/Xdd99VuX18fLyuv/56HT16VAcOHFBMTEytBgUAwBten+4/b948FRUV6YknnlBYWFiV24eFhenJJ59Ufn6+5s+fX6shAQDwltdh+/zzz9WsWTMlJSV5fedjxoxR8+bN9cknn9RkNgAAqs3rsO3du1d9+vSp9gP07t1b+/btq/Z+AADUhNdhy83NVXh4eLUfIDw8XGfOnKn2fgAA1ITXYWvSpInS0tKq/QBpaWlq0qRJtfcDAKAmvA5b586dtX79euXn53t953l5eVq3bl2VHw0AAKCueB226667Trm5uZozZ47Xdz5nzhzl5+dr9OjRNRoOAIDq8jpsd9xxh5o3b67HHntMc+bMkdvtrnRbt9utRx99VI899piaN2+u22+/vU6GBQCgKl5/QDskJERvv/22rr76as2cOVOvvvqqbrrpJl1++eVq1qyZJCkjI0NbtmzRsmXLdPToUQUHB+vtt99WSEhIvT0BAADOVa1Lag0YMEBr167VpEmTtHv3bj377LPltrEsS5LUpUsXvf766+rRo0fdTAoAgBeq/Re0ExIStHPnTq1YsULLly/Xtm3bdPLkSUlSZGSkEhISNGrUKP6KNgDAJ6odtrNGjhxJvAAADY7XJ48AAPBLQNgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCgBvh4AvzzZRWk6mf+jsotO6HRRmgpdZyRJI1tNq3SfgpIz+sG5SZkFh5VfckY2m00hARFq3qi92jp6KcAv6AJND5Q6uTdTJzYe08ndmcpMzlB+Rp4kaeL6qefd7+BHB3TgnT3KPnRafoF+iuoSra6/6aFm3ZuX2zbtu1StvOuTSu8rskszjZw/unZPBOUQNlTbwewNSs//wevtc4uztCFtqYrc+Wrk71B0o7ZyWyXKKkzVQecGpeUfUL/mNyvQz16PUwNl7VqwTUe//rFa+2x+dr32vZksf7u/WvaLlavIpdSNx5S68ZgG/XOY4q9qXeF+oXFhiq4gfKFxjhrNjvMjbKi2CHtLhQU2U3hQc4Xbm2v1sQVyy1Xp9vtPf6sid75ahXbXZU2GyGYrPQJe7C7U5vR3lV10QoedW3RJxBUX6BkAUlTXaEV0aKrIy6IU2TlK712/TO6iyr+PUzce0743k2UPt+uaV6+To1W4JCljZ7pW3vmx1s/5Rs0vb6GgsPK/oEV3b64r/ja43p4LyiJsqLZ2jj7V2v5U4TFJUvvwfp6oSVKgn13tHL21NfMjZRel1emMQFW63Nq9WtvvfWO3JKnrbxI8UZOkZt2idcn1nbRvabIOfrBfl03sVqdzovo4eQT1zs/mX+U2QX7BF2ASoGZKCkp04rtUSVKrYW3KrT+77Oi3KRdwKlSGV2yod1HBrXUsN1kHszeUOxT5g3OzJCk2tIsPJwTOz/ljttxFLtmbBCskunG59U0vjZQknT54quL9U5za+vJmFWUXyB4RrGY9miumf5xsfrZ6nftiRdhQ7zpGXKnsonT9eGaHMvIPyxEULbflUlbhcfnb/NU9cqQig+N9PSZQqbwTuZKkkGbloyZJAY0CFRQWpCJnkYpzixXYOLDM+syd6crcmV5mWUT7Jho0d1iZw5qoGw06bC6XSy+99JJiY2OVlJSkgIAGPS4qYfdvrL7RN2r7yY91suBH5ec7PesigzvIERTtw+mAqhXnF0uSAoIrP6zuHxwg5RSpOO/nsAWGBumyid3UamhrhcWXBizrwElt//d3ytyVoS/v+VTXvpakoFA+7lKXGmQpLMvSRx99pEceeUQ7duxQv379dOWVV6ply5a+Hg01kFOUoe8y3pdk0+VRo9UkOFYud4lO5B3Q/uw1OpV2VP2aj1NoYFNfjwrUqaaXRnoOU57VoneMol9poZV3faKMbWna//YedZ3cw0cTmqlBnjxSVFSknTt3KjExUZ9++qk2bdqkNWvWVOs+CgsL5XQ6y3zhwnNbLm3NXK4CV656Nhut6JD2CvQLVnBAqNo4euqS8AEqdhfo++x1vh4VqFRgo9JXYCUFlX8cwFVQUrptSGCl25zl5++nLpNKz8pMXX+sDibEuRpk2Ox2u8aOHat77rlHiYmJGj58uF555RWdPHnS6/uYO3euwsPDPV/x8byH4wunC08or+S0QgIcCq/gkGOLkEskSVkF/ONGwxXSovS9tbyM3ArXl+QXqyinSEGOoHLvr1UmLL70w9n5J/PqZkh4NMiwSVKXLl0UFxcnSXr00Uf1xRdfaOPGjV7v/+CDDyo7O9vzlZLCabi+UODKkSQF2Cq+qkjgT5fSKnYXXrCZgOpytAqXX5C/CrMKlJdePm6n9pX+0h3R3vvD6UXO0u/5gGDvQgjvNdiwnWVZlvr27avevXtr3rx5On36tFf72e12ORyOMl+48Oz+pb/p5pZkqcRdVG792Q9mNwrgvw8aroDgALXoVfoe/49fHi63/uyyuIHeHxn68asjklTuPTjUXoMPm9vtliTNnj1bH3zwgXbu3OlZZ1mWr8aClyLsLRXkFyKXVazkrK/ktko86wpKzmhP1teSpOY/HZIEGqpOE0o/a7lr4TY5f8z2LM/Yma4D7+1TUFiQ2o/pWGafvUt2KzftTJlllmXpwLt7tXfJLskmXXJDp/of/iLTIM+KPJe/f+nptSNHjlS7du30+uuvKzIyUp999pni4+N1ww03+HjCi096/iEdzN7guX32OpHrTizxLGsf3k/RjdrK3xagLk2HaVvmxzqeu0cnC1IUHhQtl1Wi04Un5LKK5AiMVjtH7wv+PHBxO7YmRTsXbPPcdheXfh+v+O2HnmXdpiYo9srSV2Et+8bq0ps7a9+byfr41vfVsm+M3MVupW4sfX+4/1+HlLtO5N4lu7XlxY1qemmkGrcMk7vIpdMHT+nM8TOy+dnU+97+iuwUVc/P9OLT4MMmlX6ezd/fX7/73e80Y8YMzZ8/X23atNHChQt9PdpFqciVp+yiE+WWn7usyPXzG+LNQzroihbjdcj5nbIKjykj/7D8bP4KCYhQi5BL1Cbscvn7/SK+FWGQgqwCndydUW75ucsKsgrKrOv95/5qckmk9r+VrNSNx+Uf6KcWfWLUbWpChX+25rJbuip1wzFlH8pS9qHTcpe41SgyRG1GtlencZ0V2blZ3T8xyGb9Ao7nZWVl6c4779SyZcs0dOhQzZgxQ1dffXW17sPpdCo8PFxXx/1BAfx5FBgqcikfa4G5inOLtHT468rOzj7veRO/mF+TW7Vqpa+++kqDBg3y9SgAgAbsFxG2Jk2a6PHHH/f1GACAX4AGf1YkAADVQdgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAowT4eoALxbIsSVKJu8jHkwD1pziX72+Y6+z399mf55WxWVVtYYijR48qPj7e12MAAGopJSVFcXFxla6/aMLmdrt1/PhxhYWFyWaz+Xqci4LT6VR8fLxSUlLkcDh8PQ5Qp/j+vvAsy1JOTo5iYmLk51f5O2kXzaFIPz+/8xYe9cfhcPAPH8bi+/vCCg8Pr3IbTh4BABiFsAEAjELYUG/sdrtmzpwpu93u61GAOsf3d8N10Zw8AgC4OPCKDQBgFMIGADAKYQMAGIWwAQCMQthQp9xut1wul6/HAHARI2yoM8nJybr11ls1YsQI/eEPf9DatWt9PRJQ5/jFreEjbKgT+/bt04ABA+RyudSnTx+tW7dO99xzj1544QVfjwbUmf379+u5555Tamqqr0fBeVw014pE/bEsS4sXL9aIESP0xhtvSJIeeughvfDCC1q4cKEKCgp0//33+3hKoHa+//57XXHFFcrKytLJkyd17733KioqytdjoQKEDbVms9l0/PhxnThxwrMsLCxMf/rTnxQcHKwlS5YoNjZWEydO9OGUQM3l5uZq7ty5GjNmjPr06aO7775bJSUluv/++4lbA0TYUCuWZclms+nyyy/XgQMHtG/fPl166aWSSuM2depU7du3Ty+//LKuv/56hYSE+HhioPr8/PzUq1cvRUZG6uabb1ZUVJTGjx8vScStAeKSWqgTBw8eVP/+/TVmzBg9//zzCg0N9UQvJSVFrVu31scff6yRI0f6elSgRnJzc9W4cWPP7TfffFMTJkzQ9OnT9cADDygyMlJut1tHjhxR27ZtfTgpeMWGOtG+fXstXbpUv/rVr9SoUSPNmjXL81tsYGCgunfv7tXfUQIaqrNRc7lc8vPz08033yzLsnTLLbfIZrNp2rRpeuqpp3TkyBG99tprHJ3wIcKGOjN06FAtW7ZMN910k1JTUzVu3Dh1795dixcvVnp6uuLj4309IlBr/v7+sixLbrdb48ePl81m06RJk/TBBx/o4MGD2rRpE1HzMQ5Fos5t2bJF9957rw4fPqyAgAD5+/tryZIl6tmzp69HA+rM2R+dNptNw4cP17Zt27Rq1Sp169bNx5OBsKFeOJ1OnTp1Sjk5OWrZsiVvrsNILpdL9913n5577jlt27ZN3bt39/VIEIciUU8cDoccDoevxwDqXZcuXbRlyxai1oDwig0AauHs2b9oOLikFgDUAlFreAgbAMAohA0AYBTCBgAwCmEDABiFsAEAjELYAABGIWyASk/ZPvfLz89PERERGjRokObNmydff9xz0aJFstlsmjVrVpnlU6ZMkc1m06pVq+rtsQ8fPiybzaYhQ4bU22MAdYmwAeeYPHmyJk+erIkTJ6pz585as2aNfv/73+uWW27x9Wj1prJoAr9UXFILOMeiRYvK3P7888917bXXasmSJZo4caKuu+463wxWiblz5+qBBx5Qq1at6u0xYmNjtWfPHq5Yj18MXrEB55GYmKhJkyZJkt577z3fDlOBli1bqlOnTvUancDAQHXq1Kle4wnUJcIGVOHsn9tJSUnxLLPZbGrTpo2Kioo0e/ZsderUSXa7XUlJSZ5t8vLyNHfuXPXs2VOhoaEKDQ1V//799b//+7+VPtaaNWt09dVXKywsTBERERoxYoQ2bNhQ6fbne48tNzdXjz/+uHr37i2Hw6HGjRurU6dOuuuuu7R//35J0pAhQ/Sb3/xGkvT3v/+9zPuMZ1+9VvUe22uvvaaBAwfK4XAoJCRE3bt319y5c1VQUHDeeb/++msNGzZMYWFhcjgcGjVqlJKTkyt9roC3OBQJVCEnJ0eSZLfbyyx3u91KSkrS119/rauuukrdu3dXZGSkJCk9PV2JiYnasWOHWrRooauuukqWZWnt2rWaMmWKNm/erBdffLHM/X300Ue6/vrrVVJSor59+6pdu3bavn27Bg8erClTplRr5tTUVCUmJmr37t1q0qSJhgwZIrvdrh9++EH//ve/dckll6hjx44aOXKkSkpKtGbNGvXo0UMJCQme++jQoUOVj3P77bfrf/7nfxQcHKxhw4YpJCREq1at0kMPPaQPP/xQK1eurPDV5Icffqjnn39evXv31rXXXqtt27bp448/1oYNG7Rr1y61aNGiWs8XKMMCYEmyKvrn4Ha7rSuuuMKSZD388MPltu/QoYN19OjRcvtde+21liTrnnvusQoKCjzLT5w4YfXu3duSZH3yySee5U6n02rWrJklyVqwYEGZx58xY4bn8WbOnFnmcSZPnmxJsr766qsyy4cPH25JssaNG2fl5OSUWXfo0CFr+/btntsLFy6s8L7P3V6SddVVV5VZ/tZbb1mSrJiYGGv//v2e5adPn7YGDhxoSbKmT59e4bx+fn7Wu+++61leUlJi3XDDDZYk65FHHqlwDsBbhA2wyoetpKTE2r9/vzVlyhRLkmW3263vv/++3PbLli0rd19bt261JFl9+vSxXC5XufVbtmyxJFljxozxLFuwYIElyRo8eHC57YuKiqy4uDivw7ZhwwZLkhUdHW05nc4qn3tNwzZ48GBLkvXKK6+U22f79u2WzWazQkNDrfz8/HLzTpw4sdw+mzdvrvBxgOriPTbgHGffXwoICFDHjh21aNEihYWF6Y033lD79u3LbTt69Ohy9/HZZ59JkpKSkuTnV/6f2Nn33DZu3OhZ9s0330iSxo8fX277wMBA3XjjjV4/h5UrV0qSJkyYoLCwMK/3q47i4mKtX79ekjRx4sRy67t3767u3bvrzJkz2rZtW7n111xzTbllHTt2lFR6GBWoDd5jA84xefJkSZKfn58cDoe6deum//qv/1KTJk3KbRsdHV3ufTep9GQLSXr44Yf18MMPV/pY555ccfz4cUlS69atK9y2TZs23j4Fz0ku/xniunTy5EkVFRUpKipKjRs3rnCbNm3aaPv27Tp27Fi5dXFxceWWnY1wYWFh3Q6Liw5hA87xn59jO5/g4OAKl7vdbknSwIED6zUuDd35/gBnRa9kgbpC2IA6dvbVSFJSkqZPn+7VPi1btpQkHTlypML1lS2vSHx8vCTp4MGDXu9TXZGRkQoKClJmZqZyc3MrfNV29pVrbGxsvc0BVIRfm4A6lpiYKEl69913vd5n0KBBkqSlS5eWW1dSUqK3337b6/u6+uqrJUlvvPGGzpw5U+X2QUFBnsfxVmBgoPr37y9JWrJkSbn1u3bt0vbt2xUaGlrmIwTAhUDYgDrWr18/JSYmas2aNbrrrrvkdDrLbbN9+3atWLHCc/umm25SZGSkVq1aVeYD3JZlaebMmfrxxx+9fvy+fftq6NChSk9P12233abc3Nwy6w8fPqydO3d6bsfExEiS9u3b5/VjSNIf//hHSdKsWbP0ww8/eJbn5OTo7rvvlmVZuv322ys9ZAvUF8IG1IPXX39dPXv21Msvv6zWrVtr6NChnmtNtmrVSgkJCWXCFhYWpvnz58vf319TpkxR//79dcstt6hr16568skn9fvf/75aj//aa6/p0ksv1RtvvKFWrVpp7NixGjdunHr16qX27dvriy++8Gzbv39/RUdH66233tKQIUM0depU/e53v9PatWvP+xg33nijbrvtNh09elRdu3bVddddp3Hjxql9+/ZavXq1+vfvr9mzZ1fv/zigDhA2oB5ER0dr7dq1euGFF9S5c2dt3bpVb731lnbs2KF27drpySef1F/+8pcy+4wdO1ZfffWVhg4dql27dmn58uVq2bKlVq9erQEDBlTr8WNjY7Vp0ybNnj1bcXFx+vzzz/XJJ58oLy9Pd955Z5mLOQcHB2v58uVKTEzUtm3btGjRIs2fP99z2a3zeeWVV7R48WL17NlTq1ev1ocffqjo6Gj94x//0JdffsmFk+ETNsvy8R+aAgCgDvGKDQBgFMIGADAKYQMAGIWwAQCMQtgAAEYhbAAAoxA2AIBRCBsAwCiEDQBgFMIGADAKYQMAGIWwAQCMQtgAAEb5/67JfnQhTLYGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " tensor([1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       " tensor([0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]),\n",
       " tensor([1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " tensor([1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1]),\n",
       " tensor([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WakeClassifierPlModule(\n",
    "    in_channels=IN_CHANNELS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    learning_rate=LEARNING_RATE\n",
    ")\n",
    "dm = xAIWakesDataModule( # self, csv_file, root_dir, batch_size, num_workers, transform=None)\n",
    "    csv_file=CSV_DIR,\n",
    "    root_dir=DATA_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    transform=TRANSFORM,\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=ACCELERATOR,\n",
    "    devices=DEVICES,\n",
    "    min_epochs=1,\n",
    "    max_epochs=NUM_EPOCHS,\n",
    "    log_every_n_steps=5,\n",
    "    inference_mode=True,\n",
    ")\n",
    "trainer.predict(\n",
    "    model=model,\n",
    "    datamodule=dm,\n",
    "    ckpt_path=rf\"epoch=19-step=160.ckpt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed9a05-8cc2-4d5c-b92c-ece0ed0eee1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
